{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27744fb-b728-4bcf-a1ed-95e702d792ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb9859d-c5ea-4de7-a43e-6a4a274c70f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Peeking at Nakuru.csv (UTF-8) ---\n",
      "Line 18491: 355;DHT22;3989;-0.296;36.048;2025-11-01T22:54:11.351548+00:00;humidity;75.10\n",
      "Line 18492 (THE PROBLEM): 355;DHT22;3989;-0.296;36.048;2025-11-01T22:54:11.351548+00:00;temperature;19,50\n",
      "Line 18493: 4940;pms5003;3994;-0.297;36.088;2025-11-01T22:54:21+00:00;P2;41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = 'Nakuru.csv'\n",
    "problem_line_number = 18492 \n",
    "\n",
    "try:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        print(f\"--- Peeking at {filename} (UTF-8) ---\")\n",
    "        for i, line in enumerate(f):\n",
    "            # i starts at 0 so we want line i = problem_line_number - 1\n",
    "            \n",
    "            # Print the line *before* the problem for context\n",
    "            if i == problem_line_number - 2: \n",
    "                print(f\"Line {i + 1}: {line.strip()}\")\n",
    "                \n",
    "            # Print the problem line\n",
    "            if i == problem_line_number - 1: \n",
    "                print(f\"Line {i + 1} (THE PROBLEM): {line.strip()}\")\n",
    "                \n",
    "            # Print the line *after* the problem\n",
    "            if i == problem_line_number: \n",
    "                print(f\"Line {i + 1}: {line.strip()}\")\n",
    "                break # stop reading the file\n",
    "\n",
    "except UnicodeDecodeError:\n",
    "    print(f\"UTF-8 failed. Trying 'latin-1' encoding...\")\n",
    "    with open(filename, 'r', encoding='latin-1') as f:\n",
    "        print(f\"--- Peeking at {filename} (latin-1) ---\")\n",
    "        for i, line in enumerate(f):\n",
    "            if i == problem_line_number - 2: \n",
    "                print(f\"Line {i + 1}: {line.strip()}\")\n",
    "            if i == problem_line_number - 1: \n",
    "                print(f\"Line {i + 1} (THE PROBLEM): {line.strip()}\")\n",
    "            if i == problem_line_number: \n",
    "                print(f\"Line {i + 1}: {line.strip()}\")\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481ed1d-9ecc-43be-aa92-d8a7eca8d623",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Cleaning\n",
    "When I first tried to load the data with `pd.read_csv('Nakuru.csv')`, I got a `ParserError`.\n",
    "After investigating the raw file, I determined the problem:\n",
    "* The data is separated by semicolons (`;`), not commas.\n",
    "* The data uses a comma (`,`) as the decimal separator.\n",
    "\n",
    "To fix this, I will specify the `sep` and `decimal` parameters when loading the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54b2ff8-fe13-427c-bada-f269dfcdf7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jupyter notebooksensor_id</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th>location</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value_type</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4956</td>\n",
       "      <td>pms5003</td>\n",
       "      <td>4007</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>36.043</td>\n",
       "      <td>2025-11-01T00:00:25+00:00</td>\n",
       "      <td>P2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4956</td>\n",
       "      <td>pms5003</td>\n",
       "      <td>4007</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>36.043</td>\n",
       "      <td>2025-11-01T00:00:25+00:00</td>\n",
       "      <td>P1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4956</td>\n",
       "      <td>pms5003</td>\n",
       "      <td>4007</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>36.043</td>\n",
       "      <td>2025-11-01T00:00:25+00:00</td>\n",
       "      <td>P0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4957</td>\n",
       "      <td>DHT22</td>\n",
       "      <td>4007</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>36.043</td>\n",
       "      <td>2025-11-01T00:00:27+00:00</td>\n",
       "      <td>humidity</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4957</td>\n",
       "      <td>DHT22</td>\n",
       "      <td>4007</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>36.043</td>\n",
       "      <td>2025-11-01T00:00:27+00:00</td>\n",
       "      <td>temperature</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jupyter notebooksensor_id sensor_type  location     lat     lon  \\\n",
       "0                       4956     pms5003      4007  -0.290  36.043   \n",
       "1                       4956     pms5003      4007  -0.290  36.043   \n",
       "2                       4956     pms5003      4007  -0.290  36.043   \n",
       "3                       4957       DHT22      4007  -0.290  36.043   \n",
       "4                       4957       DHT22      4007  -0.290  36.043   \n",
       "\n",
       "                   timestamp   value_type value  \n",
       "0  2025-11-01T00:00:25+00:00           P2    28  \n",
       "1  2025-11-01T00:00:25+00:00           P1    29  \n",
       "2  2025-11-01T00:00:25+00:00           P0    20  \n",
       "3  2025-11-01T00:00:27+00:00     humidity  99.9  \n",
       "4  2025-11-01T00:00:27+00:00  temperature  18.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Nakuru.csv', sep=';', decimal=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f26e343-1b35-488a-a608-5b74690b1d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249478 entries, 0 to 249477\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   jupyter notebooksensor_id  249478 non-null  int64 \n",
      " 1   sensor_type                249478 non-null  object\n",
      " 2   location                   249478 non-null  int64 \n",
      " 3   lat                        249478 non-null  object\n",
      " 4   lon                        249478 non-null  object\n",
      " 5   timestamp                  249478 non-null  object\n",
      " 6   value_type                 249478 non-null  object\n",
      " 7   value                      249478 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8e9e1-03ff-4693-b27a-0327b0e2b99f",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for Time Series\n",
    "From the `df.info()` output, I can see there are no null values, which is great. \n",
    "However, I need to prepare the data for modeling:\n",
    "\n",
    "1.  The `value_type` column has many different sensor readings. My goal is to analyze air quality, and the most common metric is 'P2' (PM2.5), so I will filter to focus only on 'P2' values.\n",
    "2.  The `timestamp` column is currently a string (object). I will convert it to a proper `datetime` object.\n",
    "3.  Second, I will make the `timestamp` my index for the table, which is required for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b1f009-eb1d-4d94-9c6e-e13e45bca4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  jupyter notebooksensor_id sensor_type  \\\n",
      "timestamp                                                                 \n",
      "2025-11-01 00:00:25+00:00                              4956     pms5003   \n",
      "2025-11-01 00:00:44+00:00                              4970     pms5003   \n",
      "2025-11-01 00:01:32.985897+00:00                        600     pms5003   \n",
      "2025-11-01 00:01:35.870038+00:00                        420     pms5003   \n",
      "2025-11-01 00:01:48+00:00                              4938     pms5003   \n",
      "\n",
      "                                  location     lat     lon value_type  value  \n",
      "timestamp                                                                     \n",
      "2025-11-01 00:00:25+00:00             4007  -0.290  36.043         P2     28  \n",
      "2025-11-01 00:00:44+00:00             4010  -0.310  36.070         P2     14  \n",
      "2025-11-01 00:01:32.985897+00:00      3991  -0.295  36.081         P2  30.50  \n",
      "2025-11-01 00:01:35.870038+00:00      4000  -0.307  36.064         P2  46.00  \n",
      "2025-11-01 00:01:48+00:00             3990  -0.300  36.052         P2     34  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 50192 entries, 2025-11-01 00:00:25+00:00 to 2025-11-11 19:00:29.422239+00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   jupyter notebooksensor_id  50192 non-null  int64 \n",
      " 1   sensor_type                50192 non-null  object\n",
      " 2   location                   50192 non-null  int64 \n",
      " 3   lat                        50192 non-null  object\n",
      " 4   lon                        50192 non-null  object\n",
      " 5   value_type                 50192 non-null  object\n",
      " 6   value                      50192 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_pm25 = df[df['value_type'] == 'P2'].copy()\n",
    "df_pm25['timestamp'] = pd.to_datetime(df_pm25['timestamp'], format='ISO8601')\n",
    "df_pm25.set_index('timestamp', inplace=True)\n",
    "print(df_pm25.head())\n",
    "df_pm25.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669bde1-dc12-4abd-b646-ba7dbad3ff53",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for Time Series\n",
    "\n",
    "First, I filtered the DataFrame so it will only use rows where the `value_type` is 'P2'.\n",
    "Next, I needed to make the `timestamp` the index. I successfully made the `timestamp` into a datetime format, but I got an error at first. This error made me notice that I needed to specify format=ISO8601 to handle the high-precision time.\n",
    "\n",
    "Finally, I set this new `timestamp` column as the index for the table.\n",
    "Some other problems I noticed: value, lat and lon columns are supposed to be float but it is object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b895f22-014f-493c-ba15-4af3151e4ee9",
   "metadata": {},
   "source": [
    "### 3. Fixing Column Data Types (Update)\n",
    "When I tried to convert the `value` column, I got a new `ValueError: Unable to parse string \"17.?5\"`. This tells me the column contains corrupt text.\n",
    "\n",
    "I will use `errors='coerce'`. This will force all values to become numeric and convert any corrupt strings into `NaN` (missing values), which I will handle next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c7bab9-acfe-46c9-bf49-2e1a2190b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm25['value'] = pd.to_numeric(df_pm25['value'], errors='coerce')\n",
    "df_pm25['lat'] = pd.to_numeric(df_pm25['lat'], errors='coerce')\n",
    "df_pm25['lon'] = pd.to_numeric(df_pm25['lon'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff30229f-bdf2-4749-b75f-354737b31611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  jupyter notebooksensor_id sensor_type  \\\n",
      "timestamp                                                                 \n",
      "2025-11-01 00:00:25+00:00                              4956     pms5003   \n",
      "2025-11-01 00:00:44+00:00                              4970     pms5003   \n",
      "2025-11-01 00:01:32.985897+00:00                        600     pms5003   \n",
      "2025-11-01 00:01:35.870038+00:00                        420     pms5003   \n",
      "2025-11-01 00:01:48+00:00                              4938     pms5003   \n",
      "\n",
      "                                  location    lat     lon value_type  value  \n",
      "timestamp                                                                    \n",
      "2025-11-01 00:00:25+00:00             4007 -0.290  36.043         P2   28.0  \n",
      "2025-11-01 00:00:44+00:00             4010 -0.310  36.070         P2   14.0  \n",
      "2025-11-01 00:01:32.985897+00:00      3991 -0.295  36.081         P2   30.5  \n",
      "2025-11-01 00:01:35.870038+00:00      4000 -0.307  36.064         P2   46.0  \n",
      "2025-11-01 00:01:48+00:00             3990 -0.300  36.052         P2   34.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 50192 entries, 2025-11-01 00:00:25+00:00 to 2025-11-11 19:00:29.422239+00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   jupyter notebooksensor_id  50192 non-null  int64  \n",
      " 1   sensor_type                50192 non-null  object \n",
      " 2   location                   50192 non-null  int64  \n",
      " 3   lat                        50192 non-null  float64\n",
      " 4   lon                        50192 non-null  float64\n",
      " 5   value_type                 50192 non-null  object \n",
      " 6   value                      50189 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(df_pm25.head())\n",
    "df_pm25.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217b367-c3a1-47f1-89ee-d7aacbf1d3e4",
   "metadata": {},
   "source": [
    "## 4. Handling Missing Values and Outliers\n",
    "Now that the data types are correct, I can finish cleaning hopefully.\n",
    "\n",
    "1.  Missing Values:My `df_pm25.info()` output shows I have **3 `NaN` (missing) values** (50192 total - 50189 non-null). This is a low number, so I will simply drop these 3 rows using `.dropna()`.\n",
    "\n",
    "2.  **Outliers:** As in my original project, I will remove any extreme outliers. A PM2.5 reading over 500 is almost certainly a sensor error. I will filter the DataFrame to keep only rows where the `value` is less than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "608b48c8-e727-42b6-86fa-58e27d69154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 49454 entries, 2025-11-01 00:00:25+00:00 to 2025-11-11 19:00:29.422239+00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   jupyter notebooksensor_id  49454 non-null  int64  \n",
      " 1   sensor_type                49454 non-null  object \n",
      " 2   location                   49454 non-null  int64  \n",
      " 3   lat                        49454 non-null  float64\n",
      " 4   lon                        49454 non-null  float64\n",
      " 5   value_type                 49454 non-null  object \n",
      " 6   value                      49454 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 3.0+ MB\n",
      "       jupyter notebooksensor_id      location           lat           lon  \\\n",
      "count               49454.000000  49454.000000  49454.000000  49454.000000   \n",
      "mean                 3063.556982   3995.305779     -0.284701     36.062613   \n",
      "std                  2200.896732      8.958592      0.117368      0.029381   \n",
      "min                   256.000000   3977.000000     -0.337000     35.943000   \n",
      "25%                   536.000000   3989.000000     -0.314000     36.052000   \n",
      "50%                  4932.000000   3996.000000     -0.307000     36.064000   \n",
      "75%                  4940.000000   4001.000000     -0.295000     36.070000   \n",
      "max                  4973.000000   4010.000000      0.371000     36.125000   \n",
      "\n",
      "              value  \n",
      "count  49454.000000  \n",
      "mean      40.630046  \n",
      "std       34.032573  \n",
      "min        0.000000  \n",
      "25%       19.000000  \n",
      "50%       33.000000  \n",
      "75%       50.000000  \n",
      "max      499.000000  \n"
     ]
    }
   ],
   "source": [
    "df_pm25.dropna(inplace=True)\n",
    "df_pm25 = df_pm25[df_pm25[\"value\"] < 500]\n",
    "df_pm25.info()\n",
    "print(df_pm25.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843bf65-19b7-4e77-9ddb-c3ea170c70cf",
   "metadata": {},
   "source": [
    "## 3. Timezone Localization and Resampling\n",
    "This is the final and most important cleaning step to make the data ready for modeling.\n",
    "1.  Timezone: My `df.info()` output shows the index is in UTC (it ends in `+00:00`). To analyze public health trends (like morning vs. evening pollution), I must convert this to the local time for Nakuru, which is \"Africa/Nairobi\".\n",
    "\n",
    "2.  Resampling: The data is currently at a high frequency (multiple readings per minute). To build a stable model, I will resample the data into 1-hour (`1H`) averages.\n",
    "\n",
    "3.  Filling Gaps: Resampling might create `NaN` values for any hours that had no data. I will use `.fillna(method='ffill')` to fill these gaps with the last known good value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14e9b969-741d-4f78-b4b6-322221763938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  P2\n",
      "timestamp                           \n",
      "2025-11-01 03:00:00+03:00  33.413812\n",
      "2025-11-01 04:00:00+03:00  31.719415\n",
      "2025-11-01 05:00:00+03:00  36.517940\n",
      "2025-11-01 06:00:00+03:00  55.410060\n",
      "2025-11-01 07:00:00+03:00  68.006036\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 260 entries, 2025-11-01 03:00:00+03:00 to 2025-11-11 22:00:00+03:00\n",
      "Freq: h\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   P2      260 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 4.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_pm25.index = df_pm25.index.tz_convert(\"Africa/Nairobi\")\n",
    "\n",
    "# Resampling to 1-hour averages\n",
    "df_hourly = df_pm25['value'].resample(\"1h\").mean().ffill().to_frame()\n",
    "\n",
    "df_hourly.rename(columns={'value': 'P2'}, inplace=True)\n",
    "\n",
    "print(df_hourly.head())\n",
    "\n",
    "df_hourly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36b38ea3-88d0-429d-ac2d-68895786a17c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\africa-air-quality-forecasting-Nakuru\\venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_hourly\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdf_hourly_clean.feather\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClean data saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdf_hourly_clean.feather\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\africa-air-quality-forecasting-Nakuru\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:2949\u001b[39m, in \u001b[36mDataFrame.to_feather\u001b[39m\u001b[34m(self, path, **kwargs)\u001b[39m\n\u001b[32m   2921\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2922\u001b[39m \u001b[33;03mWrite a DataFrame to the binary Feather format.\u001b[39;00m\n\u001b[32m   2923\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2945\u001b[39m \u001b[33;03m>>> df.to_feather(\"file.feather\")  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   2946\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2947\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeather_format\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_feather\n\u001b[32m-> \u001b[39m\u001b[32m2949\u001b[39m \u001b[43mto_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\africa-air-quality-forecasting-Nakuru\\venv\\Lib\\site-packages\\pandas\\io\\feather_format.py:56\u001b[39m, in \u001b[36mto_feather\u001b[39m\u001b[34m(df, path, storage_options, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_feather\u001b[39m(\n\u001b[32m     39\u001b[39m     df: DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     **kwargs: Any,\n\u001b[32m     43\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     44\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m    Write a DataFrame to the binary Feather format.\u001b[39;00m\n\u001b[32m     46\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \n\u001b[32m     55\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feather\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, DataFrame):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\africa-air-quality-forecasting-Nakuru\\venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "df_hourly.to_feather('df_hourly_clean.feather')\n",
    "print(\"Clean data saved to 'df_hourly_clean.feather'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721e06a-9004-4bea-b606-758d38d535b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
